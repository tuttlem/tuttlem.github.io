---
layout: post
title: Parquet
date: 2023-07-06
comments: false
categories: [ "" ]
---

The [Apache Parquet](https://parquet.apache.org/) file format is used widely in the data space. It's a column-oriented format that focuses on storing data as efficiently as possible, with emphasis on data retrieval.

### Why?

The most common storage format that you'd use to hold data is [CSV](https://en.wikipedia.org/wiki/Comma-separated_values). It's a good, simple format but has quite a number of short-comings when it comes to data analysis. 

[Parquet](https://parquet.apache.org/) is a column-oriented format which is much more sympathetic to data analysis. [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) is row-oriented, which is a much better application for an [OLTP](https://en.wikipedia.org/wiki/Online_transaction_processing) scenario.

[Parquet](https://parquet.apache.org/) offers compression and partitioning that is simply not available to the [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) format.

So, it stores information - but is better suited to the data warehouse idea.

### Python

A really easy way to get started using Parquet is with Python. The [PyArrow](https://arrow.apache.org/docs/python/index.html) library is a set of utilities that allow you to work with in-memory analytics tools. [PyArrow](https://arrow.apache.org/docs/python/index.html) plays nicely with [Pandas](https://pandas.pydata.org/) and [NumPy](https://numpy.org/) so it's a good fit.

Make sure you have `pyarrow` installed as a dependency.

{% highlight python %}
import pandas as pd
import numpy as np
import pyarrow as pa

import pyarrow.parquet as pq
{% endhighlight %}

### Create a table

First off, we'll create a `DataFrame` from some raw data.

{% highlight python %}
data = [
    ["John", "Smith", 23],
    ["Amber", "Brown", 31],
    ["Mark", "Green", 22],
    ["Jane", "Thomas", 26]
]

df = pd.DataFrame(
    data, 
    columns=["first_name", "last_name", "age"]
)
{% endhighlight %}

We can then use `from_pandas` function to create a `pyarrow.Table` from this `DataFrame`.

{% highlight python %}
table = pa.Table.from_pandas(df)
{% endhighlight %}

### Basic I/O

Now that we have loaded a `Table`, we can save this data using `write_table` and pick it back up off disk using `read_table`.

{% highlight python %}
pq.write_table(table, 'people.parquet')

people = pq.read_table('people.parquet')
people.to_pandas()
{% endhighlight %}

### Finishing up

There's a lot more benefits to picking a more optimal data storage solution when working in the data analytics space.


